{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd08df93",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection â€” Python Reproduction & Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f940df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_PATH = \"/mnt/data/your_creditcard.csv\"   # <-- CHANGE THIS\n",
    "TARGET_COL = \"Class\"\n",
    "ID_COLS = []\n",
    "\n",
    "import os, warnings, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve, roc_curve, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import shap, joblib\n",
    "\n",
    "assert os.path.exists(DATA_PATH), f\"Dataset not found: {DATA_PATH}\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "print(df.head())\n",
    "assert TARGET_COL in df.columns\n",
    "print(df[TARGET_COL].value_counts())\n",
    "\n",
    "if ID_COLS:\n",
    "    df = df.drop(columns=ID_COLS, errors=\"ignore\")\n",
    "\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if TARGET_COL in num_cols:\n",
    "    num_cols.remove(TARGET_COL)\n",
    "\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "y = df[TARGET_COL].astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "preprocess = ColumnTransformer([(\"num\", StandardScaler(), X_train.select_dtypes(include=[np.number]).columns.tolist())], remainder=\"drop\")\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "cw = compute_class_weight(\"balanced\", classes=classes, y=y_train)\n",
    "cw = {c:w for c,w in zip(classes, cw)}\n",
    "log_reg = LogisticRegression(max_iter=2000, class_weight=cw)\n",
    "pipe_lr = Pipeline([(\"prep\", preprocess), (\"clf\", log_reg)]).fit(X_train, y_train)\n",
    "proba_lr = pipe_lr.predict_proba(X_test)[:,1]\n",
    "print(\"LR ROC-AUC, PR-AUC:\", roc_auc_score(y_test, proba_lr), average_precision_score(y_test, proba_lr))\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=300, n_jobs=-1)\n",
    "imb_pipe_rf = ImbPipeline([(\"prep\", preprocess), (\"smote\", SMOTE(random_state=42)), (\"model\", rf)])\n",
    "param_dist = {\"model__n_estimators\":[200,300,500],\"model__max_depth\":[None,8,12,16,24],\"model__min_samples_split\":[2,5,10],\"model__min_samples_leaf\":[1,2,4],\"model__max_features\":[\"sqrt\",\"log2\",None]}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "search_rf = RandomizedSearchCV(imb_pipe_rf, param_distributions=param_dist, n_iter=12, scoring=\"average_precision\", n_jobs=-1, cv=cv, random_state=42, verbose=1).fit(X_train, y_train)\n",
    "best_rf = search_rf.best_estimator_\n",
    "proba_rf = best_rf.predict_proba(X_test)[:,1]\n",
    "print(\"RF ROC-AUC, PR-AUC:\", roc_auc_score(y_test, proba_rf), average_precision_score(y_test, proba_rf))\n",
    "\n",
    "# Calibration on the better of LR vs RF\n",
    "use_rf = average_precision_score(y_test, proba_rf) >= average_precision_score(y_test, proba_lr)\n",
    "base = best_rf if use_rf else pipe_lr\n",
    "cal = CalibratedClassifierCV(base, method=\"isotonic\", cv=5).fit(X_train, y_train)\n",
    "proba_cal = cal.predict_proba(X_test)[:,1]\n",
    "print(\"Calibrated ROC-AUC, PR-AUC:\", roc_auc_score(y_test, proba_cal), average_precision_score(y_test, proba_cal))\n",
    "\n",
    "# Threshold tuning with a cost matrix\n",
    "import numpy as np\n",
    "COST_FN, COST_FP = 25.0, 1.0\n",
    "def expected_cost(y_true, y_prob, t):\n",
    "    y_pred = (y_prob >= t).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return fp*COST_FP + fn*COST_FN\n",
    "\n",
    "thresholds = np.linspace(0.01, 0.99, 99)\n",
    "costs = [expected_cost(y_test, proba_cal, t) for t in thresholds]\n",
    "best_t = thresholds[int(np.argmin(costs))]\n",
    "print(\"Best threshold:\", best_t, \"Min expected cost:\", min(costs))\n",
    "y_pred_best = (proba_cal >= best_t).astype(int)\n",
    "print(\"Confusion matrix at best threshold:\\n\", confusion_matrix(y_test, y_pred_best))\n",
    "print(classification_report(y_test, y_pred_best, digits=4))\n",
    "\n",
    "# Save artifacts\n",
    "out_dir = \"/mnt/data/cc_fraud_outputs\"\n",
    "import os, json\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "joblib.dump(cal, os.path.join(out_dir, \"model_calibrated.joblib\"))\n",
    "joblib.dump(preprocess, os.path.join(out_dir, \"preprocess.joblib\"))\n",
    "with open(os.path.join(out_dir, \"metadata.json\"), \"w\") as f:\n",
    "    json.dump({\"best_threshold\": float(best_t)}, f, indent=2)\n",
    "\n",
    "print(\"Saved to:\", out_dir)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
